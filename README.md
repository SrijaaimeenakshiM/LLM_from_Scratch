ğŸ§  LLM from Scratch + Instruction Fine-Tuning + Spam Classifier

This repository contains educational and research-oriented projects focused on building and fine-tuning Language Models from scratch using GPT-2 weights. It includes three major components:

ğŸ“‚ Project Structure

<pre> <code> ğŸ“¦ LLM Projects Repository â”œâ”€â”€ datasets/ â”‚ â”œâ”€â”€ SMSSpamCollection â”‚ â”œâ”€â”€ instruction-data.json â”‚ â””â”€â”€ the-verdict.txt â”‚ â”œâ”€â”€ llm_from_scratch.ipynb â”œâ”€â”€ spam_classifier_from_scratch.ipynb â”œâ”€â”€ LLM_instruction_finetuning_from_scratch.ipynb â””â”€â”€ README.md </code> </pre>

ğŸ“Œ Contents

1. ğŸ”§ LLM from Scratch (llm_from_scratch.ipynb)
- Implements a basic LLM architecture (Transformer-based) from scratch.
- Tokenization logic using a Byte Pair Encoding (BPE) tokenizer built from the-verdict.txt.
- Handles out-of-vocabulary tokens and uses [endoftext].
- No pretrained model used here â€” pure educational implementation.

2. ğŸ›¡ï¸ Spam Classifier using LLM (spam_classifier_from_scratch.ipynb)
- Fine-tunes GPT-2 weights on a binary SMS spam classification task.
- Dataset: SMSSpamCollection
- Converts classification problem into an instruction-based generation task.
- Demonstrates how a generative model can be adapted for classification.

3. ğŸ“– Instruction Fine-Tuning (LLM_instruction_finetuning_from_scratch.ipynb)
- Uses instruction-data.json to fine-tune GPT-2 for instruction-following tasks.
- Aligns GPT-2 with prompt-based input/output formats.
- Prepares the model to follow commands more reliably â€” similar to how ChatGPT was aligned using instruction datasets.

ğŸ“ Datasets

All datasets are located in the datasets/ folder:
- SMSSpamCollection â€“ For spam classification.
- instruction-data.json â€“ Contains input/output pairs for instruction fine-tuning.
- the-verdict.txt â€“ Used to build a BPE tokenizer vocabulary.

ğŸ§  Goals

- Understand the internal architecture of LLMs by building from scratch.
- Explore how GPT-2 can be used for downstream tasks like classification.
- Experiment with instruction tuning to align models toward following user prompts.

ğŸš€ Future Work

- Add support for multi-class classification.
- Improve BPE tokenizer with additional pre-tokenization rules.
- Instruction fine-tuning with larger instruction datasets like Self-Instruct or FLAN.

ğŸ’¡ Acknowledgements

- Inspired by GPT-2 architecture and Hugging Face models.
- Data credits: UCI, OpenAI (for model inspiration).

ğŸ“¬ Contact

Feel free to reach out via GitHub Issues for questions, suggestions, or collaborations.
